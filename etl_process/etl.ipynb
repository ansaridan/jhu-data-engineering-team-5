{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4fbf02-4aed-4e8f-acc9-068210b5c2d8",
   "metadata": {},
   "source": [
    "# Final Project Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44866d91-3a1a-4c0c-83c5-1d91ad4abab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in base directory\n",
    "WORKDIR = \"/home/awesome\"\n",
    "import os\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "# datatypes\n",
    "import json\n",
    "import yaml\n",
    "# database connection\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import psycopg2.extensions as psql_ext\n",
    "from psycopg2 import sql\n",
    "# custom etl functions\n",
    "from etl_process import utils as etl\n",
    "# respective datasets\n",
    "from etl_process.data_processing import station_info as info\n",
    "# computation\n",
    "import pandas as pd\n",
    "# utilities\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "# typing\n",
    "from typing import Union\n",
    "\n",
    "# set up directories\n",
    "WORKDIR_PATH = Path.cwd()\n",
    "DATA_PATH = WORKDIR_PATH / 'etl_process' / 'processed_data'\n",
    "SCHEMAS_PATH = WORKDIR_PATH / 'etl_process' / 'schemas'\n",
    "\n",
    "PROJECT_SCHEMA = 'citibike_project'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db293678-68e7-45b3-b2f3-19dbcc069649",
   "metadata": {},
   "source": [
    "# Set Up Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1f09d-ad66-4cf6-b9ea-b9b6f98edea0",
   "metadata": {},
   "source": [
    "### Connect, Set up schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a69bf1d-0a60-42b8-979b-b3eead28cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSQL db connection using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    dbname='new_db', \n",
    "    user='awesome_user', \n",
    "    password='awesome_password', \n",
    "    host='postgres', \n",
    "    port='5432'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a82829-997b-42e4-886f-cd95b21be86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables in citibike_project dropped successfully.\n",
      "Dropped Schema citibike_project.\n",
      "Created Schema citibike_project.\n"
     ]
    }
   ],
   "source": [
    "etl.drop_recreate_schema(conn, PROJECT_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43507033-2240-4bd5-9845-9048aa762a27",
   "metadata": {},
   "source": [
    "### Clean all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb884185-027c-4c46-8120-8132f6e3bc01",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/etl_process/schemas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m schema_files \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m SCHEMAS_PATH\u001b[38;5;241m.\u001b[39miterdir() \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mis_file()]\n\u001b[1;32m      2\u001b[0m tables_schemas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;241m*\u001b[39m[etl\u001b[38;5;241m.\u001b[39mread_yaml_to_dict(schema_file)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m schema_file \u001b[38;5;129;01min\u001b[39;00m schema_files]))\n\u001b[1;32m      3\u001b[0m tables_schemas \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tables_schemas \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems()}\n",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m schema_files \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m SCHEMAS_PATH\u001b[38;5;241m.\u001b[39miterdir() \u001b[38;5;28;01mif\u001b[39;00m item\u001b[38;5;241m.\u001b[39mis_file()]\n\u001b[1;32m      2\u001b[0m tables_schemas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;241m*\u001b[39m[etl\u001b[38;5;241m.\u001b[39mread_yaml_to_dict(schema_file)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m schema_file \u001b[38;5;129;01min\u001b[39;00m schema_files]))\n\u001b[1;32m      3\u001b[0m tables_schemas \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tables_schemas \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1017\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m    result for the special paths '.' and '..'.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m   1019\u001b[0m             \u001b[38;5;66;03m# Yielding a path object for these makes little sense\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/etl_process/schemas'"
     ]
    }
   ],
   "source": [
    "schema_files = [item for item in SCHEMAS_PATH.iterdir() if item.is_file()]\n",
    "tables_schemas = list(itertools.chain(*[etl.read_yaml_to_dict(schema_file)[\"tables\"] for schema_file in schema_files]))\n",
    "tables_schemas = {k: v for d in tables_schemas for k, v in d.items()}\n",
    "\n",
    "for table_name, table_schema in tables_schemas.items():\n",
    "    etl.drop_recreate_table(\n",
    "        db_schema=PROJECT_SCHEMA,\n",
    "        table_name=table_name,\n",
    "        table_schema=table_schema,\n",
    "        conn=conn,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc7564-7e8c-415a-a63c-6007f47652a2",
   "metadata": {},
   "source": [
    "# Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50670da0-ad9c-45f7-bfe8-9095f292b117",
   "metadata": {},
   "source": [
    "### Aggregated Ride Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6678e6-82a1-429f-b70d-3f55926b756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 893703 records to citibike_project.citibike_station_history\n",
      "Uploaded 955062 records to citibike_project.citibike_station_history\n",
      "Uploaded 917794 records to citibike_project.citibike_station_history\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m traffic_data:\n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43metl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPROJECT_SCHEMA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitibike_station_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtables_schemas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcitibike_station_history\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/awesome/etl_process/utils.py:132\u001b[0m, in \u001b[0;36mupload_dataframe\u001b[0;34m(conn, dataframe, db_schema, table_name, table_schema)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43mpsycopg2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m         conn\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataframe)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_schema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/psycopg2/extras.py:1299\u001b[0m, in \u001b[0;36mexecute_values\u001b[0;34m(cur, sql, argslist, template, page_size, fetch)\u001b[0m\n\u001b[1;32m   1297\u001b[0m     parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1298\u001b[0m parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m post\n\u001b[0;32m-> 1299\u001b[0m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fetch:\n\u001b[1;32m   1301\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(cur\u001b[38;5;241m.\u001b[39mfetchall())\n",
      "File \u001b[0;32m/usr/lib/python3.10/encodings/utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "traffic_data = [item for item in (DATA_PATH / \"rides\" / \"station_traffic\").iterdir() if item.is_file()]\n",
    "\n",
    "for file in traffic_data:\n",
    "    df = pd.read_csv(file)\n",
    "    etl.upload_dataframe(\n",
    "        conn=conn,\n",
    "        dataframe=df,\n",
    "        db_schema=PROJECT_SCHEMA,\n",
    "        table_name=\"citibike_station_history\",\n",
    "        table_schema=tables_schemas[\"citibike_station_history\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b18e4f5-6aa3-40d2-9af9-f769a45a28d5",
   "metadata": {},
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb9607-8f04-4772-9ed2-bd2ba64fe638",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [\n",
    "    \"weather_general\",\n",
    "    \"weather_precip\",\n",
    "]:\n",
    "    df = pd.read_csv(DATA_PATH / \"weather\" / f\"{file}.csv\")\n",
    "    etl.upload_dataframe(\n",
    "        conn=conn,\n",
    "        dataframe=df,\n",
    "        db_schema=PROJECT_SCHEMA,\n",
    "        table_name=file,\n",
    "        table_schema=tables_schemas[file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6025dc-00f7-4a71-b06b-99593ec2393f",
   "metadata": {},
   "source": [
    "### Station Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564437d-f973-401d-bfc5-cf806abd00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_info = info.get_station_info_data()\n",
    "\n",
    "etl.upload_dataframe(\n",
    "    conn=conn,\n",
    "    dataframe=df_station_info,\n",
    "    db_schema=PROJECT_SCHEMA,\n",
    "    table_name='station_info',\n",
    "    table_schema=tables_schemas[\"station_info\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33d7c3-938f-4f5e-b623-83484e9237ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query(f\"SELECT * FROM {PROJECT_SCHEMA}.station_info LIMIT 3\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0274592-8062-4a37-8f74-2788c12e6378",
   "metadata": {},
   "source": [
    "### IRS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6528fc-84e9-4d26-b0c5-6b428593eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [\n",
    "    \"irs_codes\",\n",
    "    \"nyc_irs\",\n",
    "]:\n",
    "    df = pd.read_csv(DATA_PATH / \"irs\" / f\"{file}.csv\")\n",
    "    etl.upload_dataframe(\n",
    "        conn=conn,\n",
    "        dataframe=df,\n",
    "        db_schema=PROJECT_SCHEMA,\n",
    "        table_name=file,\n",
    "        table_schema=tables_schemas[file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e8c61-59de-4135-8197-700338e15f6e",
   "metadata": {},
   "source": [
    "### Close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531750f-1d3f-45a4-9990-22848db948e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d005a61-fc0e-4a92-9abc-5f66b1eb84d8",
   "metadata": {},
   "source": [
    "# Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5bf25-f62a-4dd3-a2e9-31b127a0d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_sql_query(f\"SELECT * FROM {PROJECT_SCHEMA}.station_info\", conn)\n",
    "df_largest_stations = df_stations.sort_values(by=\"capacity\", ascending=False).iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885466f8-893d-4da8-9e54-67622046ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_precip = pd.read_sql_query(f\"SELECT * FROM {PROJECT_SCHEMA}.weather_precip\", conn)\n",
    "df_weather_precip[\"one_hour_precip_amount\"] = pd.to_numeric(df_weather_precip['one_hour_precip_amount'], errors='coerce')\n",
    "df_weather_precip_daily = df_weather_precip.groupby(by=\"date\")[[\"one_hour_precip_amount\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7b127-0a6d-4aef-b3f0-bafb3ae7f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "df_stations = pd.read_sql_query(f\"SELECT * FROM {PROJECT_SCHEMA}.station_info\", conn)\n",
    "\n",
    "df_weather_precip = pd.read_sql_query(f\"SELECT * FROM {PROJECT_SCHEMA}.weather_precip\", conn)\n",
    "df_weather_precip[\"one_hour_precip_amount\"] = pd.to_numeric(df_weather_precip['one_hour_precip_amount'], errors='coerce')\n",
    "df_weather_precip_daily = df_weather_precip.groupby(by=\"date\")[[\"one_hour_precip_amount\"]].sum()\n",
    "\n",
    "# Create simple plots\n",
    "bar1 = go.Bar(x=df_weather_precip_daily.index, y=df_weather_precip_daily.one_hour_precip_amount)\n",
    "layout1 = go.Layout()\n",
    "fig1 = go.Figure([bar1], layout1)\n",
    "\n",
    "# Create another simple plot\n",
    "# Create a table\n",
    "fig2 = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=list(df_largest_stations.to_dict().keys()),\n",
    "        fill_color='paleturquoise',\n",
    "        align='left'\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=df_largest_stations.values.T,\n",
    "        fill_color='lavender',\n",
    "        align='left'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Convert figures to HTML strings\n",
    "fig1_html = fig1.to_html(full_html=False, include_plotlyjs='cdn')\n",
    "fig2_html = fig2.to_html(full_html=False, include_plotlyjs='cdn')\n",
    "\n",
    "# Create the HTML template\n",
    "template = \"\"\"\n",
    "<html>\n",
    "\n",
    "df_largest_stations = df_stations.sort_values(by=\"capacity\", ascending=False).iloc[:50]\n",
    "<head>\n",
    "    <title>Plotly Report</title>\n",
    "    <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>CitiBike Report</h1>\n",
    "    <div id='divPlotly1'>\n",
    "        <h2>Daily Precipitation</h2>\n",
    "        {fig1_html}\n",
    "    </div>\n",
    "    <div id='divPlotly2'>\n",
    "        <h2>Largest Stations</h2>\n",
    "        {fig2_html}\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Write the HTML report to a file\n",
    "with open('report.html', 'w') as f:\n",
    "    f.write(template.format(fig1_html=fig1_html, fig2_html=fig2_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d077a41-589c-4627-9dc8-3280a959401f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
